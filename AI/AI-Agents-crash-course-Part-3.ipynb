{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Crash Course Part 3\n",
    "- Before you start, create a .env file and set the OPENAI_API_KEY as follows:\n",
    "\n",
    "OPENAI_API_KEY=\"your-openai-api-key\"\n",
    "\n",
    "- Install Ollama: https://ollama.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install crewai ollama openai\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from crewai.flow.flow import Flow, listen, start\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Load environment variables (like API keys)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis Flow with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "class MovieRecommendationFlow(Flow):\n",
    "    model = \"gpt-4o-mini\"\n",
    "\n",
    "    @start()\n",
    "    def generate_genre(self):\n",
    "\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Give me a random movie genre.\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        random_genre = response.choices[0].message.content.strip()\n",
    "        return random_genre\n",
    "\n",
    "    @listen(generate_genre)\n",
    "    def recommend_movie(self, random_genre):\n",
    "    \n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Recommend a highly rated movie in the {random_genre} genre.\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        movie_recommendation = response.choices[0].message.content.strip()\n",
    "        return movie_recommendation\n",
    "\n",
    "# Execute the flow\n",
    "flow = MovieRecommendationFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis Flow with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRecommendationFlow(Flow):\n",
    "    model = \"llama3.2:1b\"\n",
    "\n",
    "    @start()\n",
    "    def generate_genre(self):\n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Give me a random movie genre.\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        random_genre = response.message.content\n",
    "        return random_genre\n",
    "\n",
    "    @listen(generate_genre)\n",
    "    def recommend_movie(self, random_genre):\n",
    "    \n",
    "        response = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Recommend a highly rated movie in the {random_genre} genre.\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        movie_recommendation = response.message.content\n",
    "\n",
    "        return movie_recommendation\n",
    "\n",
    "# Execute the flow\n",
    "flow = MovieRecommendationFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstructured States with Ollama—example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRecommendationFlow(Flow):\n",
    "\n",
    "    @start()\n",
    "    def generate_genre(self):\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.2:1b\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Give me a random movie genre.\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        random_genre = response.message.content\n",
    "        self.state[\"genre\"] = random_genre\n",
    "\n",
    "        return random_genre\n",
    "\n",
    "    @listen(generate_genre)\n",
    "    def recommend_movie(self, random_genre):\n",
    "    \n",
    "        response = ollama.chat(\n",
    "            model=\"llama3.2:1b\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Recommend a highly rated movie in the {random_genre} genre.\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        movie_recommendation = response.message.content\n",
    "        self.state[\"recommendation\"] = movie_recommendation\n",
    "        return movie_recommendation\n",
    "\n",
    "# Execute the flow\n",
    "flow = MovieRecommendationFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(flow.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured States—example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, start\n",
    "\n",
    "class TaskManagementFlow(Flow):\n",
    "\n",
    "    @start()\n",
    "    def generate_task(self):\n",
    "        print(f\"Flow started. State ID: {self.state['id']}\\n\")\n",
    "        \n",
    "        # Step 1: Generate a new task\n",
    "        self.state[\"task\"] = \"Fix a critical bug in the payment system\"\n",
    "        self.state[\"status\"] = \"Pending\"\n",
    "        print(f\"Task generated: {self.state['task']} (Status: {self.state['status']})\\n\")\n",
    "\n",
    "    @listen(generate_task)\n",
    "    def start_task(self):\n",
    "        # Step 2: Update task status to 'In Progress'\n",
    "        self.state[\"status\"] = \"In Progress\"\n",
    "        print(f\"Task status updated: {self.state['status']}\\n\")\n",
    "\n",
    "    @listen(start_task)\n",
    "    def complete_task(self):\n",
    "        # Step 3: Mark task as 'Completed'\n",
    "        self.state[\"status\"] = \"Completed\"\n",
    "        print(f\"Task status updated: {self.state['status']}\\n\")\n",
    "        pprint(f\"Final Task State: {self.state}\")\n",
    "\n",
    "# Execute the flow\n",
    "flow = TaskManagementFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, start\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Defining a structured state model\n",
    "class TaskState(BaseModel):\n",
    "    task: str = \"None\"\n",
    "    status: str = \"None\"\n",
    "\n",
    "class StructuredTaskFlow(Flow[TaskState]):\n",
    "\n",
    "    @start()\n",
    "    def generate_task(self):\n",
    "        print(f\"Flow started. State ID: {self.state.id}\\n\")\n",
    "        self.state.task = \"Develop a new API endpoint\"\n",
    "        self.state.status = \"Pending\"\n",
    "        print(f\"Task generated: {self.state.task} (Status: {self.state.status})\\n\")\n",
    "\n",
    "    @listen(generate_task)\n",
    "    def start_task(self):\n",
    "        self.state.status = \"In Progress\"\n",
    "        print(f\"Task status updated: {self.state.status}\\n\")\n",
    "\n",
    "    @listen(start_task)\n",
    "    def complete_task(self):\n",
    "        self.state.status = \"Completed\"\n",
    "        print(f\"Task status updated: {self.state.status}\\n\")\n",
    "        pprint(f\"Final Task State: {self.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the flow\n",
    "flow = StructuredTaskFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new field to the structured state model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, start\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Defining a structured state model\n",
    "class TaskState(BaseModel):\n",
    "    task: str = \"None\"\n",
    "    status: str = \"None\"\n",
    "\n",
    "class StructuredTaskFlow(Flow[TaskState]):\n",
    "\n",
    "    @start()\n",
    "    def generate_task(self):\n",
    "        print(f\"Flow started. State ID: {self.state.id}\\n\")\n",
    "        self.state.task = \"Develop a new API endpoint\"\n",
    "        self.state.status = \"Pending\"\n",
    "        self.state.priority = \"High\" # adding a new field that is not defined in the TaskState model\n",
    "        print(f\"Task generated: {self.state.task} (Status: {self.state.status})\\n\")\n",
    "\n",
    "    @listen(generate_task)\n",
    "    def start_task(self):\n",
    "        print(f\"Task status currently: {self.state.status}\\n\")\n",
    "        self.state.status = \"In Progress\"\n",
    "        print(f\"Task status updated: {self.state.status}\\n\")\n",
    "\n",
    "    @listen(start_task)\n",
    "    def complete_task(self):\n",
    "        self.state.status = \"Completed\"\n",
    "        print(f\"Task status updated: {self.state.status}\\n\")\n",
    "        pprint(f\"Final Task State: {self.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the flow and this should raise an error\n",
    "flow = StructuredTaskFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Flows—OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, or_, start\n",
    "\n",
    "class SupportFlow(Flow):\n",
    "\n",
    "    @start()\n",
    "    def live_chat_request(self):\n",
    "        return \"Support request received via live chat\"\n",
    "\n",
    "    @start()\n",
    "    def email_ticket_request(self):\n",
    "        return \"Support request received via email ticket\"\n",
    "\n",
    "    @listen(or_(live_chat_request, email_ticket_request))\n",
    "    def log_request(self, request_source):\n",
    "        print(f\"Logging request: {request_source}\")\n",
    "\n",
    "# Execute the flow\n",
    "flow = SupportFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Flows—AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, and_, listen, start\n",
    "\n",
    "class TicketEscalationFlow(Flow):\n",
    "\n",
    "    @start()\n",
    "    def user_confirms_issue(self):\n",
    "        self.state[\"user_confirmation\"] = True\n",
    "        print(\"User confirmed they still need assistance.\")\n",
    "\n",
    "    @listen(user_confirms_issue)\n",
    "    def agent_reviews_ticket(self):\n",
    "        self.state[\"agent_review\"] = True\n",
    "        print(\"Support agent has reviewed the ticket.\")\n",
    "\n",
    "    @listen(and_(user_confirms_issue, agent_reviews_ticket))\n",
    "    def escalate_ticket(self):\n",
    "        print(\"Escalating ticket to Level 2 support!\")\n",
    "\n",
    "# Execute the flow\n",
    "flow = TicketEscalationFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Flows—Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from crewai.flow.flow import Flow, listen, router, start\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class TicketState(BaseModel):\n",
    "    priority: str = \"low\"\n",
    "\n",
    "class TicketRoutingFlow(Flow[TicketState]):\n",
    "\n",
    "    @start()\n",
    "    def classify_ticket(self):\n",
    "        print(\"Classifying support ticket...\")\n",
    "        self.state.priority = random.choice([\"high\", \"low\"])\n",
    "        print(f\"Ticket classified as: {self.state.priority}\")\n",
    "\n",
    "    @router(classify_ticket)\n",
    "    def route_ticket(self):\n",
    "        return \"urgent_support\" if self.state.priority == \"high\" else \"email_support\"\n",
    "\n",
    "    @listen(\"urgent_support\")\n",
    "    def assign_to_agent(self):\n",
    "        print(\"Urgent ticket assigned to a live support agent!\")\n",
    "\n",
    "    @listen(\"email_support\")\n",
    "    def send_to_email_queue(self):\n",
    "        print(\"Non-urgent ticket sent to email support queue.\")\n",
    "\n",
    "# Execute the flow\n",
    "flow = TicketRoutingFlow()\n",
    "final_result = await flow.kickoff_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crew with Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!crewai create flow test_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add the API key to the .env file in the test_flow folder\n",
    "- Also, edit the src/test_flow/crews/poem_crew/poem_crew.py file by adding this code:\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd test_flow/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test_flow/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
