# Core utilities
requests>=2.31.0,<3.0.0
beautifulsoup4>=4.12.0,<5.0.0
PyPDF2>=3.0.0,<4.0.0
langchain>=0.2.0,<0.3.0
numpy>=1.24.0,<2.0.0

# NLP/ML stack (pinned)
# If you have an NVIDIA GPU on Linux/macOS/WSL2, pick ONE extra-index below and uncomment it
# For CUDA 12.6 wheels:
--extra-index-url https://download.pytorch.org/whl/cu126
# For CUDA 11.8 wheels:
# --extra-index-url https://download.pytorch.org/whl/cu118
torch==2.7.0
transformers==4.55.0
accelerate==1.10.0
peft==0.17.0
trl==0.20.0
sentence-transformers==5.1.0
einops>=0.7.0,<1.0.0

# FAISS (CPU by default; switch to faiss-gpu only if you know what you're doing)
faiss-cpu==1.11.0.post1

# Optional for 8-bit quantization/inference
bitsandbytes>=0.43.0